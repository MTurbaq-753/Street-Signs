{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "224b2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b61fe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 30, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def show5(img_loader):\n",
    "    dataiter = iter(img_loader)\n",
    "    \n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:10]\n",
    "    images = batch[0][0:10]\n",
    "    for i in range(10):\n",
    "        print(labels[i])\n",
    "        image = images[i].numpy()\n",
    "        print(image.shape)\n",
    "        plt.imshow(np.rot90(image.T, k=3))\n",
    "        plt.show()\n",
    "        \n",
    "# show5(trainDataLoader)\n",
    "print(trainData[2][0:10][0].numpy().shape)\n",
    "plt.imshow(np.rot90(trainData[2][0:10][0].numpy().T, k=3))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "725ca61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "    def __init__(self, numChannels, classes):\n",
    "        # call the parent constructor\n",
    "        super(LeNet, self).__init__()\n",
    "        # initialize first set of CONV => RELU => POOL layers\n",
    "        self.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
    "            kernel_size=(5, 5))\n",
    "        self.relu1 = ReLU()\n",
    "        self.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        # initialize second set of CONV => RELU => POOL layers\n",
    "        self.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
    "            kernel_size=(5, 5))\n",
    "        self.relu2 = ReLU()\n",
    "        self.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        # initialize first (and only) set of FC => RELU layers\n",
    "        self.fc1 = Linear(in_features=4320, out_features=3774)\n",
    "        self.relu3 = ReLU()\n",
    "        # initialize our softmax classifier\n",
    "        self.fc2 = Linear(in_features=3774, out_features=classes)\n",
    "        self.logSoftmax = LogSoftmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7596b764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# import the necessary packages\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from torchvision.datasets import GTSRB\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1648b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -m MODEL -p PLOT\n",
      "ipykernel_launcher.py: error: the following arguments are required: -m/--model, -p/--plot\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALHeL\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "help=\"path to output trained model\")\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, required=True,\n",
    "help=\"path to output loss/accuracy plot\")\n",
    "args = vars(ap.parse_args())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a278953",
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00fb008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_transform_list = [\n",
    "                        transforms.Resize((30,30)),\n",
    "                        transforms.RandomRotation(30),\n",
    "                        transforms.RandomHorizontalFlip(),\n",
    "                        transforms.ToTensor()\n",
    "                       ]\n",
    "\n",
    "test_transform_list = [\n",
    "                        transforms.Resize((30,30)),\n",
    "                        transforms.ToTensor()\n",
    "                      ]\n",
    "\n",
    "train_transform = transforms.Compose(train_transform_list)\n",
    "test_transform = transforms.Compose(test_transform_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb30f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the GTSRB dataset...\n",
      "[INFO] generating the train/validation split...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] loading the GTSRB dataset...\")\n",
    "trainData = GTSRB(root=\"data\", download=True,\n",
    "    transform=train_transform)\n",
    "testData = GTSRB(root=\"data\", download=True,\n",
    "    transform=test_transform)\n",
    "# calculate the train/validation split\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "numValSamples = int(len(trainData) * VAL_SPLIT)\n",
    "(trainData, valData) = random_split(trainData,\n",
    "    [numTrainSamples, numValSamples],\n",
    "    generator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8042e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataLoader = DataLoader(trainData, shuffle=True,\n",
    "batch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e828a829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the LeNet model...\n",
      "[INFO] training the network...\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] initializing the LeNet model...\")\n",
    "model = LeNet(\n",
    "    numChannels=3,\n",
    "    classes=43).to(device)\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.NLLLoss()\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "    \"train_loss\": [],\n",
    "    \"train_acc\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"val_acc\": []\n",
    "}\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a11846b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [3, 29, 30] at entry 0 and [3, 43, 43] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6868/2344534415.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mvalCorrect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# loop over the training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrainDataLoader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# send the input to the device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[1;34m(batch)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'numpy'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'string_'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects each tensor to be equal size, but got [3, 29, 30] at entry 0 and [3, 43, 43] at entry 2"
     ]
    }
   ],
   "source": [
    "for e in range(0, EPOCHS):\n",
    "    # set the model in training mode\n",
    "    model.train()\n",
    "    # initialize the total training and validation loss\n",
    "    totalTrainLoss = 0\n",
    "    totalValLoss = 0\n",
    "    # initialize the number of correct predictions in the training\n",
    "    # and validation step\n",
    "    trainCorrect = 0\n",
    "    valCorrect = 0\n",
    "    # loop over the training set\n",
    "    for (x, y) in trainDataLoader:\n",
    "        # send the input to the device\n",
    "        (x, y) = (x.to(device), y.to(device))\n",
    "        # perform a forward pass and calculate the training loss\n",
    "        pred = model(x)\n",
    "        loss = lossFn(pred, y)\n",
    "        # zero out the gradients, perform the backpropagation step,\n",
    "        # and update the weights\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        # add the loss to the total training loss so far and\n",
    "        # calculate the number of correct predictions\n",
    "        totalTrainLoss += loss\n",
    "        trainCorrect += (pred.argmax(1) == y).type(\n",
    "            torch.float).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbd7df0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
